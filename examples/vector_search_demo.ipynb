{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Search API Demo\n",
    "\n",
    "This notebook demonstrates how to use the Vector Search API client to interact with our thread-safe vector content management system. We'll walk through creating libraries, documents, and chunks, and then performing both text and vector searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and initialize the client. Make sure the API is running (either locally or in a Docker container)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "# Import the client library\n",
    "from api.client import VectorSearchClient\n",
    "\n",
    "# Initialize the client\n",
    "client = VectorSearchClient(base_url=\"http://localhost:8000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check API Health\n",
    "\n",
    "Let's first check if the API is running and healthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    health = client.health_check()\n",
    "    print(f\"API Health: {health}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"Make sure the API is running. You can start it with 'docker-compose up -d'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get API Statistics\n",
    "\n",
    "Let's check the current statistics of the API to see what's already in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = client.get_stats()\n",
    "print(\"API Statistics:\")\n",
    "print(f\"Embedding Service: {stats['embedding_service']}\")\n",
    "print(f\"Similarity Service: {stats['similarity_service']}\")\n",
    "print(f\"Content Service: {stats['content_service']}\")\n",
    "print(f\"Indexer Type: {stats['indexer_type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Library\n",
    "\n",
    "Let's create a new library to store our documents and chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique ID for the library\n",
    "library_id = f\"lib-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Create the library\n",
    "library = client.create_library(\n",
    "    id=library_id,\n",
    "    name=\"Demo Library\",\n",
    "    description=\"Library for vector search demo\"\n",
    ")\n",
    "\n",
    "print(f\"Created library: {library}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Document\n",
    "\n",
    "Now, let's create a document in our library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique ID for the document\n",
    "document_id = f\"doc-{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Create the document\n",
    "document = client.create_document(\n",
    "    id=document_id,\n",
    "    library_id=library_id,\n",
    "    title=\"Vector Search Overview\",\n",
    "    content=\"This document provides an overview of vector search techniques and applications.\",\n",
    "    metadata={\"category\": \"technical\", \"author\": \"Windsurf Team\"}\n",
    ")\n",
    "\n",
    "print(f\"Created document: {document}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Chunks\n",
    "\n",
    "Let's create several chunks with different content to demonstrate the search capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample chunks for our document\n",
    "chunk_texts = [\n",
    "    \"Vector search is a technique for finding similar items in a dataset based on their vector representations.\",\n",
    "    \"Embeddings are numerical representations of text, images, or other data that capture semantic meaning.\",\n",
    "    \"Cosine similarity is a common metric used to measure the similarity between two vectors in a vector space.\",\n",
    "    \"Thread safety ensures that concurrent operations don't cause data corruption or race conditions.\",\n",
    "    \"Suffix arrays enable efficient substring searches with O(P log T + k) time complexity.\",\n",
    "    \"Tries are tree data structures optimized for prefix matching and autocomplete functionality.\",\n",
    "    \"Inverted indices map terms to documents, enabling fast word-based searches and boolean queries.\",\n",
    "    \"TF-IDF (Term Frequency-Inverse Document Frequency) is a numerical statistic used in information retrieval.\",\n",
    "    \"Dimensionality reduction techniques like random projection can compress high-dimensional vectors.\",\n",
    "    \"Content management systems organize and store digital content with metadata and search capabilities.\"\n",
    "]\n",
    "\n",
    "# Create chunks\n",
    "chunks = []\n",
    "for i, text in enumerate(chunk_texts):\n",
    "    chunk_id = f\"chunk-{uuid.uuid4().hex[:8]}\"\n",
    "    chunk = client.create_chunk(\n",
    "        id=chunk_id,\n",
    "        document_id=document_id,\n",
    "        text=text,\n",
    "        position=i,\n",
    "        metadata={\"index\": i, \"length\": len(text)}\n",
    "    )\n",
    "    chunks.append(chunk)\n",
    "    print(f\"Created chunk {i+1}: {chunk['message']}\")\n",
    "\n",
    "print(f\"\\nCreated {len(chunks)} chunks successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search\n",
    "\n",
    "Now let's perform a vector search to find chunks similar to a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector search query\n",
    "query = \"How do vector embeddings work for semantic search?\"\n",
    "\n",
    "# Perform vector search\n",
    "vector_results = client.vector_search(\n",
    "    query_text=query,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(f\"Vector search results for query: '{query}'\\n\")\n",
    "for i, result in enumerate(vector_results):\n",
    "    print(f\"Result {i+1}:\")\n",
    "    print(f\"  Score: {result['score']:.4f}\")\n",
    "    print(f\"  Text: {result['chunk']['text']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Search\n",
    "\n",
    "Let's also try text search with different indexers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text search queries\n",
    "text_queries = [\n",
    "    {\"query\": \"vector\", \"indexer\": \"suffix\"},\n",
    "    {\"query\": \"vector\", \"indexer\": \"trie\"},\n",
    "    {\"query\": \"vector\", \"indexer\": \"inverted\"}\n",
    "]\n",
    "\n",
    "# Perform text searches with different indexers\n",
    "for query_info in text_queries:\n",
    "    query = query_info[\"query\"]\n",
    "    indexer = query_info[\"indexer\"]\n",
    "    \n",
    "    text_results = client.text_search(\n",
    "        query=query,\n",
    "        indexer_type=indexer\n",
    "    )\n",
    "    \n",
    "    print(f\"Text search results for query: '{query}' using {indexer} indexer\\n\")\n",
    "    for i, result in enumerate(text_results):\n",
    "        print(f\"Result {i+1}:\")\n",
    "        print(f\"  Text: {result['chunk']['text']}\")\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Let's compare the performance of vector search vs. text search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries for performance testing\n",
    "performance_queries = [\n",
    "    \"vector similarity search\",\n",
    "    \"embedding techniques for text\",\n",
    "    \"efficient data structures\",\n",
    "    \"thread safety in concurrent systems\",\n",
    "    \"content management and organization\"\n",
    "]\n",
    "\n",
    "# Measure performance\n",
    "results = {\n",
    "    \"query\": [],\n",
    "    \"vector_time\": [],\n",
    "    \"vector_results\": [],\n",
    "    \"suffix_time\": [],\n",
    "    \"suffix_results\": [],\n",
    "    \"trie_time\": [],\n",
    "    \"trie_results\": [],\n",
    "    \"inverted_time\": [],\n",
    "    \"inverted_results\": []\n",
    "}\n",
    "\n",
    "for query in performance_queries:\n",
    "    results[\"query\"].append(query)\n",
    "    \n",
    "    # Vector search\n",
    "    start_time = time.time()\n",
    "    vector_results = client.vector_search(query_text=query, top_k=5)\n",
    "    vector_time = time.time() - start_time\n",
    "    results[\"vector_time\"].append(vector_time)\n",
    "    results[\"vector_results\"].append(len(vector_results))\n",
    "    \n",
    "    # Suffix array search\n",
    "    start_time = time.time()\n",
    "    suffix_results = client.text_search(query=query, indexer_type=\"suffix\")\n",
    "    suffix_time = time.time() - start_time\n",
    "    results[\"suffix_time\"].append(suffix_time)\n",
    "    results[\"suffix_results\"].append(len(suffix_results))\n",
    "    \n",
    "    # Trie search\n",
    "    start_time = time.time()\n",
    "    trie_results = client.text_search(query=query, indexer_type=\"trie\")\n",
    "    trie_time = time.time() - start_time\n",
    "    results[\"trie_time\"].append(trie_time)\n",
    "    results[\"trie_results\"].append(len(trie_results))\n",
    "    \n",
    "    # Inverted index search\n",
    "    start_time = time.time()\n",
    "    inverted_results = client.text_search(query=query, indexer_type=\"inverted\")\n",
    "    inverted_time = time.time() - start_time\n",
    "    results[\"inverted_time\"].append(inverted_time)\n",
    "    results[\"inverted_results\"].append(len(inverted_results))\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot search times\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a bar chart for search times\n",
    "x = range(len(df[\"query\"]))\n",
    "width = 0.2\n",
    "\n",
    "plt.bar(x, df[\"vector_time\"], width=width, label=\"Vector Search\")\n",
    "plt.bar([i + width for i in x], df[\"suffix_time\"], width=width, label=\"Suffix Array\")\n",
    "plt.bar([i + 2*width for i in x], df[\"trie_time\"], width=width, label=\"Trie\")\n",
    "plt.bar([i + 3*width for i in x], df[\"inverted_time\"], width=width, label=\"Inverted Index\")\n",
    "\n",
    "plt.xlabel(\"Query\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "plt.title(\"Search Time Comparison\")\n",
    "plt.xticks([i + 1.5*width for i in x], df[\"query\"], rotation=45, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot result counts\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a bar chart for result counts\n",
    "plt.bar(x, df[\"vector_results\"], width=width, label=\"Vector Search\")\n",
    "plt.bar([i + width for i in x], df[\"suffix_results\"], width=width, label=\"Suffix Array\")\n",
    "plt.bar([i + 2*width for i in x], df[\"trie_results\"], width=width, label=\"Trie\")\n",
    "plt.bar([i + 3*width for i in x], df[\"inverted_results\"], width=width, label=\"Inverted Index\")\n",
    "\n",
    "plt.xlabel(\"Query\")\n",
    "plt.ylabel(\"Number of Results\")\n",
    "plt.title(\"Search Result Count Comparison\")\n",
    "plt.xticks([i + 1.5*width for i in x], df[\"query\"], rotation=45, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Finally, let's clean up by deleting the resources we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete chunks\n",
    "for chunk in chunks:\n",
    "    chunk_id = chunk[\"chunk\"][\"id\"]\n",
    "    result = client.delete_chunk(chunk_id)\n",
    "    print(f\"Deleted chunk {chunk_id}: {result['message']}\")\n",
    "\n",
    "# Delete document\n",
    "result = client.delete_document(document_id)\n",
    "print(f\"Deleted document {document_id}: {result['message']}\")\n",
    "\n",
    "# Delete library\n",
    "result = client.delete_library(library_id)\n",
    "print(f\"Deleted library {library_id}: {result['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the Vector Search API client to interact with our thread-safe vector content management system. We've shown how to:\n",
    "\n",
    "1. Create libraries, documents, and chunks\n",
    "2. Perform vector searches for semantic similarity\n",
    "3. Perform text searches with different indexers (suffix array, trie, inverted index)\n",
    "4. Compare the performance of different search methods\n",
    "\n",
    "The system provides a powerful and flexible way to manage and search content using both traditional text search and modern vector search techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
